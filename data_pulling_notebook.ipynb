{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e317de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import twitter_samples, stopwords, movie_reviews\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist, classify, NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef221d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "#creating the API object while passing in auth information\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32937a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_list = [\"screen_name\", \"name\", \"location\", \"bio\", \"tweet\",\n",
    "                      \"he/him\", \"she/her\", \"they/them\",\n",
    "                      \"it/its\", \"xe/xem\", \"ze/zir\"]\n",
    "\n",
    "query_list = [\"thembo\",\"bimbo\",\"himbo\",\"theydies\",\"ladies\", \"gentlethem\", \"gentlemen\", \"theybie\", \"transgender\",\"transwoman\",\"transman\"]\n",
    "res_dict = {} \n",
    "\n",
    "#english language tweets\n",
    "language = \"en\"\n",
    "#can set number of tweets to pull - up to 100\n",
    "numTweets = 100\n",
    "#calling the user_timeline function with our parameters\n",
    "for query in query_list:\n",
    "    res_dict[query] = api.search_tweets(q=query, lang=language, count=numTweets)\n",
    "\n",
    "#needs to not matter if they use caps or not\n",
    "#function to search through tweets\n",
    "#def searchTweet(x):\n",
    "for query in query_list:   \n",
    "    users_df = pd.DataFrame(columns = user_features_list)\n",
    "    pro_they = []\n",
    "    pro_he = []\n",
    "    pro_she = []\n",
    "    pro_it = []\n",
    "    pro_xe = []\n",
    "    pro_ze = []\n",
    "    no_pronouns = []\n",
    "    authors = []\n",
    "#no pronouns, but uses nb or genderqueer\n",
    "    nbgq = []\n",
    "    tweets = []\n",
    "    for tweet in res_dict[query]: #there has to be a way to make this less redundant\n",
    "        #prints the username, tweet w query, and bio description\n",
    "        tweets.append(tweet.text)\n",
    "        #print(tweet.user.screen_name,\"Tweeted:\",tweet.text,\"| User Description:\",tweet.user.description)\n",
    "        authors.append(tweet.user.screen_name)\n",
    "        #this searches for they/them\n",
    "        if re.search((r'\\bthey\\b' or r'\\bthem\\b'), tweet.user.description, re.IGNORECASE):\n",
    "            pro_they.append(tweet.user.screen_name) #searches for they/them\n",
    "        if re.search((r'\\bthey\\b' or r'\\bthem\\b'), tweet.user.location, re.IGNORECASE):\n",
    "            pro_they.append(tweet.user.screen_name) #searches for they/them\n",
    "        if re.search((r'\\bshe\\b' or r'\\bher\\b'), tweet.user.description, re.IGNORECASE):\n",
    "            pro_she.append(tweet.user.screen_name)\n",
    "        if re.search((r'\\bshe\\b' or r'\\bher\\b'), tweet.user.location, re.IGNORECASE):\n",
    "            pro_she.append(tweet.user.screen_name)\n",
    "        if re.search((r'\\bhe\\b' or r'\\bhim\\b'), tweet.user.description, re.IGNORECASE):\n",
    "            pro_he.append(tweet.user.screen_name)\n",
    "        if re.search((r'\\bhe\\b' or r'\\bhim\\b'), tweet.user.location, re.IGNORECASE):\n",
    "            pro_he.append(tweet.user.screen_name)\n",
    "        if re.search((r'\\bit\\b' or r'\\bits\\b'), tweet.user.description, re.IGNORECASE):\n",
    "            pro_it.append(tweet.user.screen_name)\n",
    "        if re.search((r'\\bit\\b' or r'\\bits\\b'), tweet.user.location, re.IGNORECASE):\n",
    "            pro_it.append(tweet.user.screen_name)\n",
    "        if re.search((r'\\bxe\\b' or r'\\bxir\\b' or r'\\bxem\\b' or r'\\bxey\\b'), tweet.user.description, re.IGNORECASE):\n",
    "            pro_xe.append(tweet.user.screen_name)\n",
    "        if re.search((r'\\bxe\\b' or r'\\bxir\\b' or r'\\bxem\\b' or r'\\bxey\\b'), tweet.user.location, re.IGNORECASE):\n",
    "            pro_xe.append(tweet.user.screen_name)\n",
    "        if re.search((r'\\bze\\b' or r'\\bzir\\b' or r'\\bzem\\b'), tweet.user.description, re.IGNORECASE):\n",
    "            pro_ze.append(tweet.user.screen_name)\n",
    "        if re.search((r'\\bze\\b' or r'\\bzir\\b' or r'\\bzem\\b'), tweet.user.location, re.IGNORECASE):\n",
    "            pro_ze.append(tweet.user.screen_name)\n",
    "            #de,dem\n",
    "   #people who use words like genderqueer, nb\n",
    "        if re.search((r'\\bnonbinary\\b' or r'\\bgenderqueer\\b'), tweet.user.description, re.IGNORECASE):\n",
    "           nbgq.append(tweet.user.screen_name)\n",
    "           \n",
    "    for tweet in res_dict[query]: #this may not be necessary    \n",
    "    # Create empty dict\n",
    "        user_features = {}\n",
    "    # Get user data\n",
    "        user_features['bio'] = tweet.user.description\n",
    "        user_features['screen_name'] = tweet.user.screen_name\n",
    "        user_features['name'] = tweet.user.name\n",
    "        user_features['tweet'] = tweet.text\n",
    "        user_features['location'] = tweet.user.location\n",
    "        #fills in the yeses\n",
    "        if tweet.user.screen_name in pro_they:\n",
    "            user_features['they/them'] = 'yes'\n",
    "        if tweet.user.screen_name in pro_he:\n",
    "            user_features['he/him'] = 'yes'\n",
    "        if tweet.user.screen_name in pro_she:\n",
    "            user_features['she/her'] = 'yes'\n",
    "        if tweet.user.screen_name in pro_it:\n",
    "            user_features['it/its'] = 'yes'\n",
    "        if tweet.user.screen_name in pro_xe:\n",
    "            user_features['xe/xem'] = 'yes'\n",
    "        if tweet.user.screen_name in pro_ze:\n",
    "            user_features['ze/zem'] = 'yes'\n",
    "        #fills in the nos\n",
    "        if tweet.user.screen_name not in pro_he:\n",
    "            user_features['he/him'] = 'no'\n",
    "        if tweet.user.screen_name not in pro_she:\n",
    "            user_features['she/her'] = 'no'\n",
    "        if tweet.user.screen_name not in pro_xe:\n",
    "            user_features['xe/xem'] = 'no'\n",
    "        if tweet.user.screen_name not in pro_they:\n",
    "            user_features['they/them'] = 'no'\n",
    "        if tweet.user.screen_name not in pro_it:\n",
    "            user_features['it/its'] = 'no'\n",
    "        if tweet.user.screen_name not in pro_ze:\n",
    "            user_features['ze/zir'] = 'no'\n",
    "        # concat the dfs\n",
    "        user = pd.DataFrame(user_features, index = [0])\n",
    "        users_df = pd.concat([users_df, user], ignore_index = True)\n",
    "    date_string = '11_9'\n",
    "    filename = '%s_%s.csv' % (query, date_string)   \n",
    "    users_df.to_csv(filename, encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
